In this section, we analyze the literature about automatic document processing, focusing on the available datasets, and the document classification methods. We intend to justify the relevance and direction of this work by pointing the limitations of each dataset and classification framework, defining the boundaries of the gap we intend to solve.

\section{Document Understanding}

Document Understanding is a broad field encompassing various tasks that aim to extract and interpret information from multimodal documents, which may contain text, tables, images, and complex layouts~\cite{formUnderstandingSurvey}. The increasing digitization of documents has led to significant advancements in document analysis techniques, particularly through deep learning and transformer-based architectures. Among the key challenges in this domain is handling the inherent complexity of scanned documents, which often exhibit noise, structural variability, and diverse formatting styles.

Several fundamental tasks define the scope of document understanding. \textit{Document Layout Analysis} (DLA) involves detecting and categorizing different structural components of a document, such as text blocks, tables, images, and forms, to facilitate higher-level information extraction~\cite{zhong2019publaynet}. \gls{IE} focuses on retrieving relevant information, such as named entities and key-value pairs, from structured and unstructured document sources~\cite{formUnderstandingSurvey}. 

% Datasets and benchmarks have been developed to evaluate \glspl{DLA} and form understanding tasks, including FUNSD\cite{funsd2019}, CORD\cite{cord2019}, and SROIE\cite{huang_sroie_2019}, as highlighted in prior research~\cite{formUnderstandingSurvey}. These datasets focus on various aspects such as structured information extraction, OCR robustness, and structural parsing, providing essential baselines for model evaluation. However, while these benchmarks contribute to assessing specific tasks in document understanding, they do not fully address the challenges of layout-based similarity classification as explored in this work.

\section{Document Understanding Databases}

One this work's main contributions is the creation of a dataset specialized in both visual features ZSL separation. Following this, this subsection reviews existing datasets commonly used for document classification and discusses their limitations in supporting zero-shot scenarios. By analyzing these datasets, we aim to highlight the need for a new benchmark that explicitly enforces zero-shot constraints. 

The IIT-CDIP dataset~\cite{iitcdip2006}, introduced in 2006, is a large-scale repository used for document classification and information retrieval. It originated from the Tobacco Documents Library, from UCSF Industry Documents Library collection, and contains millions of scanned documents. The most popular dataset when working with document-image classification is the RVL-CDIP dataset~\cite{harley2015rvlcdip}, which was introduced in 2015. This dataset is a labeled subset of the IIT-CDIP dataset, and organized 400,000 document images into 16 predefined categories such as letters, forms, and emails. This classification is driven by the document's purpose and uses, which hinders the performance of a ZSL model trained from scratch, with no real-world knowledge.

More recently, the DocVQA dataset~\cite{mathew2021docvqa} was introduced, leveraging a subset of documents from the same collection. It comprises over 12,000 document images paired with 50,000 question-answer pairs, designed to evaluate modelsâ€™ abilities in visual question answering (VQA) on document images. DocVQA has since become a standard benchmark for assessing the performance of large language models (LLMs) in document understanding tasks, particularly in multimodal reasoning scenarios. FUNSD dataset~\cite{funsd2019}, introduced in 2019, has been widely used for OCR-based semantic relation extraction from scanned forms. Similarly, SROIE~\cite{huang_icdar2019}, CORD~\cite{cord2019} and XFUND~\cite{xfund2021} target key-value pair extraction in receipts and invoices, focusing on structured entity retrieval, such as store names, monetary values, and transaction dates. While these tasks consider the organization of visual elements within documents, they do not address \glspl{VDM} as they are designed to extract specific content rather than compare the visual similarity between different documents.

While existing datasets have contributed to document understanding research, they primarily support tasks related to text extraction, classification, and structured information retrieval. These datasets do not provide a framework for evaluating \glspl{VDM}, as their organization is often driven by textual or semantic content rather than visual arrangement.

\section{Document Processing}

In the domain of document analysis, various studies have addressed challenges related to document layout analysis, classification with limited data, and similarity detection. Understanding these works provides valuable insights into the current landscape and highlights the unique contributions of our research.

Veneri et. al.~\cite{veneri2022document} propose a method for \glspl{DLA} using Variational Autoencoders to detect deviations from a standard document template. Their approach is particularly suited for industrial compliance verification, where identifying visual discrepancies such as stamps, handwritten annotations, and misplaced signatures is crucial. By learning the distribution of compliant documents, the model detects anomalies as out-of-distribution samples, making it effective for scenarios with highly imbalanced datasets. While this study shares similarities with our work in identifying visual differences across documents, it is focused on anomaly detection within a predefined template rather than assessing layout similarity between different document classes.% Furthermore, their experiments were conducted on a private dataset, tailored for a specific industrial setting.

Scius et. al.~\cite{scius2024zeroshot} investigate the application of \glspl{LLM}, such as GPT-4 and RoBERTa, for zero-shot prompting and few-shot fine-tuning in document image classification. Their study demonstrates that \glspl{LLM} can achieve competitive performance with minimal labeled data, challenging the traditional reliance on large annotated datasets. Similarly, Sinha et al.~\cite{sinha2024cica} introduce CICA, a framework that enhances CLIP's performance in zero-shot classification by improving textual-visual feature alignment through content-injected contrastive learning. Both studies emphasize data-efficient approaches to document classification. However, their approach is not suitable for a from-scratch training, and relies on costly pretrained models, such as LLMs, limiting the potential to create a zero-shot cost-efficient model.

Another study by Landeghem et. al.~\cite{van2024distildoc} explores for visually rich document (VRD) applications, particularly \glspl{DLA}. The study evaluates multiple architectures, including ResNet, Vision Transformer (ViT), and Document Image Transformer (DiT). To assess model robustness and generalization, the authors conducted a zero-shot layout-aware evaluation on the DocVQA database, examining the impact of distilled \glspl{DLA} models in extracting logical structure from documents.

Zeghidi et al.~\cite{zeghidi2023cdpsim} present CDP-Sim, a similarity metric learning approach designed to detect counterfeit \glspl{CDP} using a Siamese neural network. This method effectively distinguishes original from fake \glspl{CDP} by learning a similarity metric that captures subtle differences between patterns. While their work is specifically applied to counterfeit detection, the concept of learning similarity metrics through metric learning and Siamese networks is broadly applicable to various tasks requiring fine-grained visual differentiation. This principle can also be leveraged in scenarios involving document layout comparisons, where structural relationships between documents must be assessed independently of their textual content.

Collectively, these studies contribute to advancements in document analysis through anomaly detection, data-efficient classification, and similarity learning. Our research builds upon these foundations by specifically addressing the challenge of \glspl{VDM}.